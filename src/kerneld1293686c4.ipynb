{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install albumentations --user > /dev/null 2>&1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install pretrainedmodels --user > /dev/null 2>&1","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np \nimport pandas as pd \nimport os\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mplimg\nfrom matplotlib.pyplot import imshow\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\n\nimport torch\nfrom torch.utils.data import TensorDataset, DataLoader,Dataset\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport time \nimport tqdm\nfrom PIL import Image\ntrain_on_gpu = True\nfrom torch.utils.data.sampler import SubsetRandomSampler\nfrom torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR\n\nimport warnings\nwarnings.simplefilter(\"ignore\", category=DeprecationWarning)\n\nfrom collections import OrderedDict\nimport cv2\nimport albumentations\nfrom albumentations import torch as AT\nimport pretrainedmodels\nimport csv\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(device)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df = pd.read_csv(\"../input/train.csv\")\ntrain_df.head()\n#test_df = pd.read_csv(\"../test.csv\")\n#test_df.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(f\"There are {len(os.listdir('../input/train'))} images in train dataset with {train_df.Id.nunique()} unique classes.\")\n#print(f\"There are {len(os.listdir('./data/test'))} images in test dataset with {test_df.Id.nunique()} unique classes.\")\n      ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.Id.value_counts().head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for i in range(1, 4):\n    print(f'There are {train_df.Id.value_counts()[train_df.Id.value_counts().values==i].shape[0]} classes with {i} samples in train data.')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(train_df.Id)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_df.Id.value_counts()[1:].plot(kind='hist');\nplt.title('Distribution of classes excluding new_whale');","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_transforms = transforms.Compose([\n                                      transforms.Resize((100, 100)),\n                                      transforms.ToTensor(),\n                                      transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                                             std=[0.229, 0.224, 0.225])\n    ])\ndata_transforms_test = transforms.Compose([\n                                           transforms.Resize((100, 100)),\n                                           transforms.ToTensor(),\n                                           transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                                                 std=[0.229, 0.224, 0.225])\n])\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"def prepare_labels(y):\n    # From here: https://www.kaggle.com/pestipeti/keras-cnn-starter\n    values = np.array(y)\n    label_encoder = LabelEncoder()\n    integer_encoded = label_encoder.fit_transform(values)\n\n    onehot_encoder = OneHotEncoder(sparse=False)\n    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n\n    y = onehot_encoded\n    return y, label_encoder","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y, le = prepare_labels(train_df['Id'])\n# y_test, le_test = prepare_labels(test_df['Id'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class WhaleDataset(Dataset):\n    def __init__(self, datafolder, datatype='train', df=None, transform = transforms.Compose([transforms.ToTensor()]), y=None):\n        self.datafolder = datafolder\n        self.datatype = datatype\n        self.y = y\n        if self.datatype == 'train':\n            self.df = df.values\n        self.image_files_list = [s for s in os.listdir(datafolder)]\n        self.transform = transform\n\n\n    def __len__(self):\n        return len(self.image_files_list)\n    \n    def __getitem__(self, idx):\n        if self.datatype == 'train':\n            img_name = os.path.join(self.datafolder, self.df[idx][0])\n            label = self.y[idx]\n            \n        elif self.datatype == 'test':\n            img_name = os.path.join(self.datafolder, self.image_files_list[idx])\n            label = np.zeros((5005,))\n\n        image = Image.open(img_name).convert('RGB')\n        image = self.transform(image)\n        if self.datatype == 'train':\n            return image, label\n        elif self.datatype == 'test':\n            # so that the images will be in a correct order\n            return image, label, self.image_files_list[idx]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_dataset = WhaleDataset(datafolder='../input/train/', datatype='train', df=train_df, transform=data_transforms, y=y)\n#test_set = WhaleDataset(datafolder='./data/test/', datatype='test', transform=data_transforms_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"train_sampler = SubsetRandomSampler(list(range(len(os.listdir('../input/train/')))))\nbatch_size = 512\nnum_workers = 0\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(3, 32, 7, padding=1)\n        self.conv2_bn = nn.BatchNorm2d(32)\n        self.pool = nn.MaxPool2d(2, 2)\n        \n        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)        \n        self.pool2 = nn.AvgPool2d(3, 3)\n        \n        self.fc1 = nn.Linear(64 * 4 * 4 * 16, 1024)\n        self.fc2 = nn.Linear(1024, 5005)\n\n        self.dropout = nn.Dropout(0.5)        \n\n    def forward(self, x):\n        x = self.pool(F.relu(self.conv2_bn(self.conv1(x))))\n        x = self.pool2(F.relu(self.conv2(x)))\n        x = x.view(-1, 64 * 4 * 4 * 16)\n        x = F.relu(self.fc1(x))\n        x = self.dropout(x)\n        x = self.fc2(x)\n\n        return x","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_conv = Net()\n\ncriterion = nn.BCEWithLogitsLoss()\n\noptimizer = optim.Adam(model_conv.parameters(), lr=0.01)\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_conv.cuda()\nn_epochs = 10\nacc = [0] * (n_epochs + 1)\ntotal = list(0. for i in range(train_df.Id.nunique()))\ncorrect = list(0. for i in range(train_df.Id.nunique()))\nllloss = [0] * (n_epochs + 1)\n\nfor epoch in range(1, n_epochs+1):\n    print(time.ctime(), 'Epoch:', epoch)\n\n    train_loss = []\n    exp_lr_scheduler.step()\n    accuracy = []\n    for batch_i, (data, target) in enumerate(train_loader):\n        #print(batch_i)\n        data, target = data.cuda(), target.cuda()\n\n        optimizer.zero_grad()\n        output = model_conv(data)\n        predicted = torch.argmax(output, 1)\n        #_, predicted = torch.max(output.data, 1)\n        res = (predicted == torch.argmax(target, 1)).squeeze()\n        for label_idx in range(len(target)):\n            label_single = torch.argmax(target, 1)[label_idx]\n                \n            correct[label_single] += res[label_idx].item()\n            total[label_single] += 1\n\n        \n        loss = criterion(output, target.float())\n        train_loss.append(loss.item())\n        ##error[epoch] += np.sum(predicted == ) \n        loss.backward()\n        optimizer.step()\n    llloss[epoch] = np.mean(train_loss)\n    acc[epoch] = sum(correct)/sum(total)\n    print(f'Epoch {epoch}, train loss: {llloss[epoch]}, acc : {acc[epoch]}')\n    \nacc_base_train = acc\nloss_base_train = llloss","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class ClassificationStatsManager(nt.StatsManager):\n    \n    def __init__(self):\n        super(ClassificationStatsManager, self).__init__()\n        \n    def init(self):\n        super(ClassificationStatsManager, self).init()\n        self.running_accuracy = 0\n        \n    def accumulate(self, loss, x, y, d): \n        super(ClassificationStatsManager, self).accumulate(loss, x, y, d) \n        _, l = torch.max(y, 1)\n        self.running_accuracy += torch.mean((l == d).float())\n        \n    def summarize(self):\n        loss = super(ClassificationStatsManager, self).summarize()\n        accuracy = 100 * (self.running_accuracy / self.number_update)\n        return {'loss': loss, 'accuracy': accuracy}","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"lr = 1e-3\nnet = model_conv\nnet = net.to(device)\nadam = torch.optim.Adam(net.parameters(), lr=lr)\nstats_manager = ClassificationStatsManager()\nexp1 = nt.Experiment(net, train_set, val_set, adam, stats_manager,\noutput_dir=\"birdclass1\", perform_validation_during_training=True)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Pretrain"},{"metadata":{"trusted":true},"cell_type":"code","source":"class WhaleDataset(Dataset):\n    def __init__(self, datafolder, datatype='train', df=None, transform = transforms.Compose([transforms.ToTensor()]), y=None\n                ):\n        self.datafolder = datafolder\n        self.datatype = datatype\n        self.y = y\n        if self.datatype == 'train':\n            self.df = df.values\n        self.image_files_list = [s for s in os.listdir(datafolder)]\n        self.transform = transform\n\n\n    def __len__(self):\n        return len(self.image_files_list)\n    \n    def __getitem__(self, idx):\n        if self.datatype == 'train':\n            img_name = os.path.join(self.datafolder, self.df[idx][0])\n            label = self.y[idx]\n            \n        elif self.datatype == 'test':\n            img_name = os.path.join(self.datafolder, self.image_files_list[idx])\n            label = np.zeros((5005,))\n\n        img = cv2.imread(img_name)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        image = self.transform(image=img)\n        image = image['image']\n        if self.datatype == 'train':\n            return image, label\n        elif self.datatype == 'test':\n            # so that the images will be in a correct order\n            return image, label, self.image_files_list[idx]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"data_transforms = albumentations.Compose([\n    albumentations.Resize(160, 320),\n    albumentations.HorizontalFlip(),\n    albumentations.RandomBrightness(),\n    albumentations.ShiftScaleRotate(rotate_limit=15, scale_limit=0.10),\n    albumentations.JpegCompression(80),\n    albumentations.HueSaturationValue(),\n    albumentations.Normalize(),\n    AT.ToTensor()\n    ])\ndata_transforms_test = albumentations.Compose([\n    albumentations.Resize(160, 320),\n    albumentations.Normalize(),\n    AT.ToTensor()\n    ])\n\ntrain_dataset = WhaleDataset(datafolder='../input/train/', datatype='train', df=train_df, transform=data_transforms, y=y)\ntest_set = WhaleDataset(datafolder='../input/test/', datatype='test', transform=data_transforms_test)\n\ntrain_sampler = SubsetRandomSampler(list(range(len(os.listdir('../input/train')))))\nvalid_sampler = SubsetRandomSampler(list(range(len(os.listdir('../input/test')))))\nbatch_size = 10\nnum_workers = 2\n# prepare data loaders (combine dataset and sampler)\ntrain_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n#valid_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\ntest_loader = torch.utils.data.DataLoader(test_set, batch_size=10, num_workers=num_workers)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_conv = pretrainedmodels.resnext101_64x4d()\nmodel_conv.avg_pool = nn.AvgPool2d((5,10))\nmodel_conv.last_linear = nn.Linear(model_conv.last_linear.in_features, 5005)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model_conv.cuda()\ncriterion = nn.BCEWithLogitsLoss()\n\noptimizer = optim.Adam(model_conv.parameters(), lr=0.01)\nexp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"n_epochs = 4\nfor epoch in range(1, n_epochs+1):\n    print(time.ctime(), 'Epoch:', epoch)\n\n    train_loss = []\n    \n\n    for batch_i, (data, target) in enumerate(train_loader):\n        # print(f'Batch {batch_i} of 50')\n        data, target = data.cuda(), target.cuda()\n\n        optimizer.zero_grad()\n        output = model_conv(data)\n        loss = criterion(output, target.float())\n        train_loss.append(loss.item())\n\n        loss.backward()\n        optimizer.step()\n    exp_lr_scheduler.step()\n\n    print(f'Epoch {epoch}, train loss: {np.mean(train_loss):.4f}')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# submission"},{"metadata":{"trusted":true},"cell_type":"code","source":"sub = pd.read_csv('../input/sample_submission.csv')\n\nmodel_conv.eval()\nfor (data, target, name) in test_loader:\n    data = data.cuda()\n    output = model_conv(data)\n    output = output.cpu().detach().numpy()\n    for i, (e, n) in enumerate(list(zip(output, name))):\n        sub.loc[sub['Image'] == n, 'Id'] = ' '.join(le.inverse_transform(e.argsort()[-5:][::-1]))\n        \nsub.to_csv('submission.csv', index=False)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.4","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}