{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install albumentations --user > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pretrainedmodels --user > /dev/null 2>&1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mplimg\n",
    "from matplotlib.pyplot import imshow\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader,Dataset\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "import time \n",
    "import tqdm\n",
    "from PIL import Image\n",
    "train_on_gpu = True\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.optim.lr_scheduler import StepLR, ReduceLROnPlateau, CosineAnnealingLR\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", category=DeprecationWarning)\n",
    "\n",
    "from collections import OrderedDict\n",
    "import cv2\n",
    "import albumentations\n",
    "from albumentations import torch as AT\n",
    "import pretrainedmodels\n",
    "import csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cfb8c68dc.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>66bf04895.jpg</td>\n",
       "      <td>w_b27b6c6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d6a92a7f9.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a37e5cc98.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2a215f11e.jpg</td>\n",
       "      <td>new_whale</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Image         Id\n",
       "0  cfb8c68dc.jpg  new_whale\n",
       "1  66bf04895.jpg  w_b27b6c6\n",
       "2  d6a92a7f9.jpg  new_whale\n",
       "3  a37e5cc98.jpg  new_whale\n",
       "4  2a215f11e.jpg  new_whale"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"./data/train.csv\")\n",
    "train_df.head()\n",
    "test_df = pd.read_csv(\"./data/test.csv\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 20289 images in train dataset with 4571 unique classes.\n",
      "There are 5073 images in test dataset with 1956 unique classes.\n"
     ]
    }
   ],
   "source": [
    "print(f\"There are {len(os.listdir('./data/train'))} images in train dataset with {train_df.Id.nunique()} unique classes.\")\n",
    "print(f\"There are {len(os.listdir('./data/test'))} images in test dataset with {test_df.Id.nunique()} unique classes.\")\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "new_whale    7728\n",
       "w_23a388d      60\n",
       "w_9b5109b      55\n",
       "w_0369a5c      54\n",
       "w_9c506f6      52\n",
       "Name: Id, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.Id.value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 2182 classes with 1 samples in train data.\n",
      "There are 1085 classes with 2 samples in train data.\n",
      "There are 441 classes with 3 samples in train data.\n"
     ]
    }
   ],
   "source": [
    "for i in range(1, 4):\n",
    "    print(f'There are {train_df.Id.value_counts()[train_df.Id.value_counts().values==i].shape[0]} classes with {i} samples in train data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.Id.value_counts()[1:].plot(kind='hist');\n",
    "plt.title('Distribution of classes excluding new_whale');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = transforms.Compose([\n",
    "                                      transforms.Resize((100, 100)),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                             std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "data_transforms_test = transforms.Compose([\n",
    "                                           transforms.Resize((100, 100)),\n",
    "                                           transforms.ToTensor(),\n",
    "                                           transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                                                 std=[0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_labels(y):\n",
    "    # From here: https://www.kaggle.com/pestipeti/keras-cnn-starter\n",
    "    values = np.array(y)\n",
    "    label_encoder = LabelEncoder()\n",
    "    integer_encoded = label_encoder.fit_transform(values)\n",
    "\n",
    "    onehot_encoder = OneHotEncoder(sparse=False)\n",
    "    integer_encoded = integer_encoded.reshape(len(integer_encoded), 1)\n",
    "    onehot_encoded = onehot_encoder.fit_transform(integer_encoded)\n",
    "\n",
    "    y = onehot_encoded\n",
    "    return y, label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "/opt/conda/lib/python3.6/site-packages/sklearn/preprocessing/_encoders.py:368: FutureWarning: The handling of integer data will change in version 0.22. Currently, the categories are determined based on the range [0, max(values)], while in the future they will be determined based on the unique values.\n",
      "If you want the future behaviour and silence this warning, you can specify \"categories='auto'\".\n",
      "In case you used a LabelEncoder before this OneHotEncoder to convert the categories to integers, then you can now use the OneHotEncoder directly.\n",
      "  warnings.warn(msg, FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "y, le = prepare_labels(train_df['Id'])\n",
    "y_test, le_test = prepare_labels(test_df['Id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WhaleDataset(Dataset):\n",
    "    def __init__(self, datafolder, datatype='train', df=None, transform = transforms.Compose([transforms.ToTensor()]), y=None\n",
    "                ):\n",
    "        self.datafolder = datafolder\n",
    "        self.datatype = datatype\n",
    "        self.y = y\n",
    "        if self.datatype == 'train':\n",
    "            self.df = df.values\n",
    "        self.image_files_list = [s for s in os.listdir(datafolder)]\n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.datatype == 'train':\n",
    "            img_name = os.path.join(self.datafolder, self.df[idx][0])\n",
    "            label = self.y[idx]\n",
    "            \n",
    "        elif self.datatype == 'test':\n",
    "            img_name = os.path.join(self.datafolder, self.image_files_list[idx])\n",
    "            label = np.zeros((1956,))\n",
    "\n",
    "        img = cv2.imread(img_name)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        image = self.transform(image=img)\n",
    "        image = image['image']\n",
    "        if self.datatype == 'train':\n",
    "            return image, label\n",
    "        elif self.datatype == 'test':\n",
    "            # so that the images will be in a correct order\n",
    "            return image, label, self.image_files_list[idx]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = WhaleDataset(datafolder='./data/train/', datatype='train', df=train_df, transform=data_transforms, y=y)\n",
    "test_set = WhaleDataset(datafolder='./data/test/', datatype='test', transform=data_transforms_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sampler = SubsetRandomSampler(list(range(len(os.listdir('./data/train/')))))\n",
    "batch_size = 512\n",
    "num_workers = 0\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, 7, padding=1)\n",
    "        self.conv2_bn = nn.BatchNorm2d(32)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)        \n",
    "        self.pool2 = nn.AvgPool2d(3, 3)\n",
    "        \n",
    "        self.fc1 = nn.Linear(64 * 4 * 4 * 16, 1024)\n",
    "        self.fc2 = nn.Linear(1024, 4571)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.5)        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv2_bn(self.conv1(x))))\n",
    "        x = self.pool2(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 4 * 4 * 16)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv = Net()\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "\n",
    "optimizer = optim.Adam(model_conv.parameters(), lr=0.01)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue May 21 16:22:48 2019 Epoch: 1\n",
      "0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 3.01 GiB (GPU 0; 10.91 GiB total capacity; 10.05 GiB already allocated; 161.38 MiB free; 8.51 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-7061d143f7d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-67-c48e05e871ec>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2_bn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m4\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             exponential_average_factor, self.eps)\n\u001b[0m\u001b[1;32m     77\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[0;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[1;32m   1621\u001b[0m     return torch.batch_norm(\n\u001b[1;32m   1622\u001b[0m         \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1623\u001b[0;31m         \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1624\u001b[0m     )\n\u001b[1;32m   1625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 3.01 GiB (GPU 0; 10.91 GiB total capacity; 10.05 GiB already allocated; 161.38 MiB free; 8.51 MiB cached)"
     ]
    }
   ],
   "source": [
    "model_conv.cuda()\n",
    "n_epochs = 10\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    print(time.ctime(), 'Epoch:', epoch)\n",
    "\n",
    "    train_loss = []\n",
    "    exp_lr_scheduler.step()\n",
    "\n",
    "    for batch_i, (data, target) in enumerate(train_loader):\n",
    "        print(batch_i)\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model_conv(data)\n",
    "        loss = criterion(output, target.float())\n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch {epoch}, train loss: {np.mean(train_loss):.4f}')\n",
    "\n",
    "# sub = pd.read_csv('../input/sample_submission.csv')\n",
    "\n",
    "# model_conv.eval()\n",
    "# for (data, target, name) in test_loader:\n",
    "#     data = data.cuda()\n",
    "#     output = model_conv(data)\n",
    "#     output = output.cpu().detach().numpy()\n",
    "#     for i, (e, n) in enumerate(list(zip(output, name))):\n",
    "#         sub.loc[sub['Image'] == n, 'Id'] = ' '.join(le.inverse_transform(e.argsort()[-5:][::-1]))\n",
    "        \n",
    "# sub.to_csv('basic_model.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WhaleDataset(Dataset):\n",
    "    def __init__(self, datafolder, datatype='train', df=None, transform = transforms.Compose([transforms.ToTensor()]), y=None\n",
    "                ):\n",
    "        self.datafolder = datafolder\n",
    "        self.datatype = datatype\n",
    "        self.y = y\n",
    "        if self.datatype == 'train':\n",
    "            self.df = df.values\n",
    "        self.image_files_list = [s for s in os.listdir(datafolder)]\n",
    "        self.transform = transform\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if self.datatype == 'train':\n",
    "            img_name = os.path.join(self.datafolder, self.df[idx][0])\n",
    "            label = self.y[idx]\n",
    "            \n",
    "        elif self.datatype == 'test':\n",
    "            img_name = os.path.join(self.datafolder, self.image_files_list[idx])\n",
    "            label = np.zeros((1956,))\n",
    "\n",
    "        img = cv2.imread(img_name)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        image = self.transform(image=img)\n",
    "        image = image['image']\n",
    "        if self.datatype == 'train':\n",
    "            return image, label\n",
    "        elif self.datatype == 'test':\n",
    "            # so that the images will be in a correct order\n",
    "            return image, label, self.image_files_list[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transforms = albumentations.Compose([\n",
    "    albumentations.Resize(160, 320),\n",
    "    albumentations.HorizontalFlip(),\n",
    "    albumentations.RandomBrightness(),\n",
    "    albumentations.ShiftScaleRotate(rotate_limit=15, scale_limit=0.10),\n",
    "    albumentations.JpegCompression(80),\n",
    "    albumentations.HueSaturationValue(),\n",
    "    albumentations.Normalize(),\n",
    "    AT.ToTensor()\n",
    "    ])\n",
    "data_transforms_test = albumentations.Compose([\n",
    "    albumentations.Resize(160, 320),\n",
    "    albumentations.Normalize(),\n",
    "    AT.ToTensor()\n",
    "    ])\n",
    "\n",
    "train_dataset = WhaleDataset(datafolder='./data/train/', datatype='train', df=train_df, transform=data_transforms, y=y)\n",
    "##test_set = WhaleDataset(datafolder='../input/test/', datatype='test', transform=data_transforms_test)\n",
    "\n",
    "train_sampler = SubsetRandomSampler(list(range(len(os.listdir('./data/train')))))\n",
    "valid_sampler = SubsetRandomSampler(list(range(len(os.listdir('./data/test')))))\n",
    "batch_size = 10\n",
    "num_workers = 2\n",
    "# prepare data loaders (combine dataset and sampler)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler, num_workers=num_workers)\n",
    "#valid_loader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, sampler=valid_sampler, num_workers=num_workers)\n",
    "#test_loader = torch.utils.data.DataLoader(test_set, batch_size=10, num_workers=num_workers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# model_conv = torchvision.models.resnet101(pretrained=True)\n",
    "# for i, param in model_conv.named_parameters():\n",
    "#     param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_layer = nn.Sequential(OrderedDict([\n",
    "#                            ('fc1', nn.Linear(2048, 1024)),\n",
    "#                            ('relu', nn.ReLU()),\n",
    "#                            ('dropout', nn.Dropout(0.1)),\n",
    "#                            ('fc2', nn.Linear(1024, 4251)),\n",
    "#                            ]))\n",
    "# model_conv.fc = final_layer\n",
    "# model_conv.fc = nn.Linear(2048, 4251)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv = pretrainedmodels.resnext101_64x4d()\n",
    "model_conv.avg_pool = nn.AvgPool2d((5,10))\n",
    "model_conv.last_linear = nn.Linear(model_conv.last_linear.in_features, 4571)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_conv.cuda()\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model_conv.parameters(), lr=0.01)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue May 21 16:22:31 2019 Epoch: 1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 7.88 MiB (GPU 0; 10.91 GiB total capacity; 10.14 GiB already allocated; 1.38 MiB free; 8.50 MiB cached)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-63-639d94884ade>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_conv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mtrain_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pretrainedmodels/models/resnext.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/container.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_modules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m             \u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    487\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    488\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 489\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    490\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    491\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pretrainedmodels/models/resnext_features/resnext101_64x4d_features.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mLambdaReduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLambdaBase\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlambda_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward_prepare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m resnext101_64x4d_features = nn.Sequential(#Sequential,\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/pretrainedmodels/models/resnext_features/resnext101_64x4d_features.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    462\u001b[0m                 \u001b[0mLambda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#Identity,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    463\u001b[0m             ),\n\u001b[0;32m--> 464\u001b[0;31m             \u001b[0mLambdaReduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m#CAddTable,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    465\u001b[0m             \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m         ),\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 7.88 MiB (GPU 0; 10.91 GiB total capacity; 10.14 GiB already allocated; 1.38 MiB free; 8.50 MiB cached)"
     ]
    }
   ],
   "source": [
    "n_epochs = 4\n",
    "for epoch in range(1, n_epochs+1):\n",
    "    print(time.ctime(), 'Epoch:', epoch)\n",
    "\n",
    "    train_loss = []\n",
    "    \n",
    "\n",
    "    for batch_i, (data, target) in enumerate(train_loader):\n",
    "        # print(f'Batch {batch_i} of 50')\n",
    "        data, target = data.cuda(), target.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model_conv(data)\n",
    "        loss = criterion(output, target.float())\n",
    "        train_loss.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    exp_lr_scheduler.step()\n",
    "\n",
    "    print(f'Epoch {epoch}, train loss: {np.mean(train_loss):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
